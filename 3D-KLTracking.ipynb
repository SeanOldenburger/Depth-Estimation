{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "from IPython. display import clear_output\n",
    "import time\n",
    "from mycolorpy import colorlist as mcp\n",
    "import PIL\n",
    "from Superstuff.matching import Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "pred = matcher({'image0': grayL_t, 'image1': grayR_t})\n",
    "\n",
    "# get sections from output (pred)\n",
    "kp1 = pred['keypoints0'][0].cpu().numpy()\n",
    "kp2 = pred['keypoints1'][0].cpu().numpy()\n",
    "matches = pred['matches0'][0].cpu().numpy()\n",
    "confidence = pred['matching_scores0'][0].detach().cpu().numpy()\n",
    "\n",
    "# keep only the valid matches and make points from found kp\n",
    "valid = matches > -1\n",
    "pts1 = kp1[valid]\n",
    "pts2 = kp2[matches[valid]]\n",
    "\n",
    "# plot kp and matches betwwen 2 images\n",
    "color = cm.jet(confidence[valid])\n",
    "text = ['SuperGlue',\n",
    "    'Keypoints: {}:{}'.format(len(kp1), len(kp2)),\n",
    "    'Matches: {}'.format(len(pts1))]\n",
    "\n",
    "out = make_matching_plot_fast(\n",
    "            grayL, grayR, kp1, kp2, pts1, pts2, color, text,\n",
    "            path=None, show_keypoints=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-indication",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matching_plot_fast(image0, image1, kpts0, kpts1, mkpts0,\n",
    "                            mkpts1, color, text, path=None,\n",
    "                            show_keypoints=False, margin=10,\n",
    "                            opencv_display=False, opencv_title='',\n",
    "                            small_text=[]):\n",
    "    H0, W0 = image0.shape\n",
    "    H1, W1 = image1.shape\n",
    "    H, W = max(H0, H1), W0 + W1 + margin\n",
    "\n",
    "    out = 255*np.ones((H, W), np.uint8)\n",
    "    out[:H0, :W0] = image0\n",
    "    out[:H1, W0+margin:] = image1\n",
    "    out = np.stack([out]*3, -1)\n",
    "\n",
    "    if show_keypoints:\n",
    "        kpts0, kpts1 = np.round(kpts0).astype(int), np.round(kpts1).astype(int)\n",
    "        white = (255, 255, 255)\n",
    "        black = (0, 0, 0)\n",
    "        for x, y in kpts0:\n",
    "            cv2.circle(out, (x, y), 2, black, -1, lineType=cv2.LINE_AA)\n",
    "            cv2.circle(out, (x, y), 1, white, -1, lineType=cv2.LINE_AA)\n",
    "        for x, y in kpts1:\n",
    "            cv2.circle(out, (x + margin + W0, y), 2, black, -1,\n",
    "                       lineType=cv2.LINE_AA)\n",
    "            cv2.circle(out, (x + margin + W0, y), 1, white, -1,\n",
    "                       lineType=cv2.LINE_AA)\n",
    "\n",
    "    mkpts0, mkpts1 = np.round(mkpts0).astype(int), np.round(mkpts1).astype(int)\n",
    "    color = (np.array(color[:, :3])*255).astype(int)[:, ::-1]\n",
    "    for (x0, y0), (x1, y1), c in zip(mkpts0, mkpts1, color):\n",
    "        c = c.tolist()\n",
    "        cv2.line(out, (x0, y0), (x1 + margin + W0, y1),\n",
    "                 color=c, thickness=1, lineType=cv2.LINE_AA)\n",
    "        # display line end-points as circles\n",
    "        cv2.circle(out, (x0, y0), 2, c, -1, lineType=cv2.LINE_AA)\n",
    "        cv2.circle(out, (x1 + margin + W0, y1), 2, c, -1,\n",
    "                   lineType=cv2.LINE_AA)\n",
    "\n",
    "    # Scale factor for consistent visualization across scales.\n",
    "    sc = min(H / 640., 2.0)\n",
    "\n",
    "    # Big text.\n",
    "    Ht = int(30 * sc)  # text height\n",
    "    txt_color_fg = (255, 255, 255)\n",
    "    txt_color_bg = (0, 0, 0)\n",
    "    for i, t in enumerate(text):\n",
    "        cv2.putText(out, t, (int(8*sc), Ht*(i+1)), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    1.0*sc, txt_color_bg, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, t, (int(8*sc), Ht*(i+1)), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    1.0*sc, txt_color_fg, 1, cv2.LINE_AA)\n",
    "\n",
    "    # Small text.\n",
    "    Ht = int(18 * sc)  # text height\n",
    "    for i, t in enumerate(reversed(small_text)):\n",
    "        cv2.putText(out, t, (int(8*sc), int(H-Ht*(i+.6))), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    0.5*sc, txt_color_bg, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, t, (int(8*sc), int(H-Ht*(i+.6))), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    0.5*sc, txt_color_fg, 1, cv2.LINE_AA)\n",
    "\n",
    "    if path is not None:\n",
    "        cv2.imwrite(str(path), out)\n",
    "\n",
    "    if opencv_display:\n",
    "        cv2.imshow(opencv_title, out)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    ax.imshow(out)\n",
    "    ax.set_title(opencv_title)\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_stereo_video(left_name, right_name, start_loss=20, end_loss=20, display=True):\n",
    "    # load in video file\n",
    "    left_vid = cv2.VideoCapture(left_name)\n",
    "    right_vid = cv2.VideoCapture(right_name)\n",
    "    \n",
    "    # print some specs\n",
    "    fps = right_vid.get(5)\n",
    "    frame_count = right_vid.get(7)\n",
    "    print(\"Loaded in video:\\nFPS: {} \\tFrame Count: {}\".format(int(fps), int(frame_count)-end_loss-start_loss))\n",
    "    \n",
    "    # convert to arrays\n",
    "    left_array = []\n",
    "    ret = True\n",
    "    while ret == True:\n",
    "        ret, frame = left_vid.read()\n",
    "        if frame is not None:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            left_array.append(frame)\n",
    "    left_array = np.array(left_array)\n",
    "    left_array = left_array[start_loss:-end_loss]\n",
    "    print(\"Left Array Loaded  | Size: {}\".format(left_array.shape))\n",
    "\n",
    "    right_array = []\n",
    "    ret = True\n",
    "    while ret == True:\n",
    "        ret, frame = right_vid.read()\n",
    "        if frame is not None:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            right_array.append(frame)\n",
    "    right_array = np.array(right_array)\n",
    "    right_array = right_array[start_loss:-end_loss]\n",
    "    print(\"Right Array Loaded | Size: {}\".format(left_array.shape))\n",
    "    \n",
    "    if display:\n",
    "        plt.imshow(left_array[0])\n",
    "        plt.title(\"First Frame:\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    \n",
    "    return left_array, right_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_points(left_array, right_array, display=True):\n",
    "    # convert to tensor\n",
    "    # set first frame and first points for left and right\n",
    "    l_frame1 = left_array[0]\n",
    "    l_frame1_gray = cv2.cvtColor(l_frame1, cv2.COLOR_RGB2GRAY)\n",
    "    l_frame1_gray_t = torch.Tensor(l_frame1_gray).reshape((1,1,480,640))\n",
    "\n",
    "    r_frame1 = right_array[0]\n",
    "    r_frame1_gray = cv2.cvtColor(r_frame1, cv2.COLOR_RGB2GRAY)\n",
    "    r_frame1_gray_t = torch.Tensor(r_frame1_gray).reshape((1,1,480,640))\n",
    "    \n",
    "    # use superpoint and superglue to find some points:\n",
    "    config = {\n",
    "            'superpoint': {\n",
    "                'nms_radius': 2,\n",
    "                'keypoint_threshold': 0,  # 1e-30\n",
    "                'max_keypoints': -1\n",
    "            },\n",
    "            'superglue': {\n",
    "                'weights': 'indoor',\n",
    "                'sinkhorn_iterations': 20,\n",
    "                'match_threshold': 0.01, # was 0.2\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # initializing matcher\n",
    "    matcher = Matching(config).eval()#.to(device)\n",
    "    \n",
    "    # finding matching points in first frame for l and r\n",
    "    pred = matcher({'image0': l_frame1_gray_t, 'image1': r_frame1_gray_t})\n",
    "\n",
    "    # get sections from output (pred)\n",
    "    l_kp = pred['keypoints0'][0].cpu().numpy()\n",
    "    r_kp = pred['keypoints1'][0].cpu().numpy()\n",
    "    matches = pred['matches0'][0].cpu().numpy()\n",
    "    confidence = pred['matching_scores0'][0].detach().cpu().numpy()\n",
    "\n",
    "    # keep only the valid matches and make points from found kp\n",
    "    valid = matches > -1\n",
    "    l_pts = l_kp[valid]\n",
    "    r_pts = r_kp[matches[valid]]\n",
    "\n",
    "    # plot kp and matches betwwen 2 images\n",
    "    color = cm.jet(confidence[valid])\n",
    "    text = ['SuperGlue',\n",
    "        'Keypoints: {}:{}'.format(len(l_kp), len(r_kp)),\n",
    "        'Matches: {}'.format(len(l_pts))]\n",
    "    \n",
    "    # view matches found\n",
    "    if display:\n",
    "        out = make_matching_plot_fast(\n",
    "                    l_frame1_gray, r_frame1_gray, l_kp, r_kp, l_pts, r_pts, color, text,\n",
    "                    path=None, show_keypoints=True)\n",
    "    \n",
    "    return l_frame1, r_frame1, l_pts, r_pts, l_frame1_gray, r_frame1_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_object_point(n, nadd, l_pts, r_pts, l_frame1, r_frame1):\n",
    "    # Create some random colors (100 of them)\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    # copies for drawing on\n",
    "    left_c = l_frame1.copy()\n",
    "    right_c = r_frame1.copy()\n",
    "\n",
    "    # left drawing\n",
    "    for i in l_pts[n:n+nadd]:\n",
    "        point = (i[0].astype(int), i[1].astype(int))\n",
    "        left_c = cv2.circle(left_c, point, 2, (255,0,0), -1)\n",
    "\n",
    "    # right drawing\n",
    "    for i in r_pts[n:n+nadd]:\n",
    "        point = (i[0].astype(int), i[1].astype(int))\n",
    "        right_c = cv2.circle(right_c, point, 2, (255,0,0), -1)\n",
    "\n",
    "    # plot left and right\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    ax.imshow(np.hstack([left_c, right_c]))\n",
    "    ax.set_title('Left -> Right')\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    return n, nadd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate optical flow using Lucas-Kadane algo from opencv\n",
    "def KLT(left_array, right_array, l_frame1, r_frame1, l_frame1_gray, r_frame1_gray, l_pts, r_pts, n, nadd=1, display=True):\n",
    "    # Create some random colors (100 of them)\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "    \n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict( winSize  = (15, 15),\n",
    "                      maxLevel = 2,\n",
    "                      criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    \n",
    "    # copying arrays for drawing purposes:\n",
    "    left_array_c = left_array.copy()\n",
    "    right_array_c = right_array.copy()\n",
    "    \n",
    "    # tracking the point: \n",
    "    # setting initial point\n",
    "    l_points1 = l_pts[n:n+nadd].reshape(-1, 1, 2)\n",
    "    r_points1 = r_pts[n:n+nadd].reshape(-1, 1, 2)\n",
    "\n",
    "    # mask for drawing purposes\n",
    "    l_mask = np.zeros_like(l_frame1)\n",
    "    r_mask = np.zeros_like(r_frame1)\n",
    "\n",
    "    l_saved_points = [l_points1]\n",
    "    r_saved_points = [r_points1]\n",
    "\n",
    "    l_saved_imgs = [l_frame1]\n",
    "    r_saved_imgs = [r_frame1]\n",
    "    l_mask_imgs = [l_mask]\n",
    "    r_mask_imgs = [r_mask]\n",
    "\n",
    "    # create a loop to iteravily go through each frame: (starting from the second frame)\n",
    "    for l_frame2, r_frame2 in zip(left_array_c[1:], right_array_c[1:]):\n",
    "        l_frame2_gray = cv2.cvtColor(l_frame2, cv2.COLOR_RGB2GRAY)\n",
    "        r_frame2_gray = cv2.cvtColor(r_frame2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        l_points2, l_status, l_error = cv2.calcOpticalFlowPyrLK(l_frame1_gray, l_frame2_gray, l_points1, None, **lk_params)\n",
    "        r_points2, r_status, r_error = cv2.calcOpticalFlowPyrLK(r_frame1_gray, r_frame2_gray, r_points1, None, **lk_params)\n",
    "\n",
    "        # Select good points (if status = 1 therefore found point in next frame)\n",
    "        if l_points2 is not None:\n",
    "            l_good_new = l_points2[l_status==1]\n",
    "            l_good_old = l_points1[l_status==1]\n",
    "        if r_points2 is not None:\n",
    "            r_good_new = r_points2[r_status==1]\n",
    "            r_good_old = r_points1[r_status==1]\n",
    "\n",
    "        # draw the tracks\n",
    "        for i, (new, old) in enumerate(zip(l_good_new, l_good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            l_mask = cv2.line(l_mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "            l_frame2 = cv2.circle(l_frame2, (int(a), int(b)), 2, color[i].tolist(), -1)\n",
    "        l_img = cv2.add(l_frame2, l_mask)\n",
    "        for i, (new, old) in enumerate(zip(r_good_new, r_good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            r_mask = cv2.line(r_mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "            r_frame2 = cv2.circle(r_frame2, (int(a), int(b)), 2, color[i].tolist(), -1)\n",
    "        r_img = cv2.add(r_frame2, r_mask)\n",
    "\n",
    "        # Now update the previous frame and previous points\n",
    "        l_frame1_gray = l_frame2_gray.copy()\n",
    "        l_points1 = l_good_new.reshape(-1, 1, 2)\n",
    "        r_frame1_gray = r_frame2_gray.copy()\n",
    "        r_points1 = r_good_new.reshape(-1, 1, 2)\n",
    "\n",
    "        # save points\n",
    "        l_saved_points.append(l_points1)\n",
    "        r_saved_points.append(r_points1)\n",
    "\n",
    "        # save imgs\n",
    "        l_saved_imgs.append(l_img)\n",
    "        r_saved_imgs.append(r_img)\n",
    "\n",
    "        # save masks\n",
    "        l_mask_imgs.append(l_mask)\n",
    "        r_mask_imgs.append(r_mask)\n",
    "    \n",
    "    if display:\n",
    "        fig, ax = plt.subplots(1,2,figsize=(20,20))\n",
    "        ax[0].imshow(l_mask)\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[1].imshow(r_mask)\n",
    "        ax[1].axis(\"off\")\n",
    "        plt.show()\n",
    "        \n",
    "    return l_saved_points, r_saved_points, l_saved_imgs, r_saved_imgs, l_mask_imgs, r_mask_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_3D(l_saved_points, r_saved_points, display=\"base\", disp_limit=1):\n",
    "    # camera baselines\n",
    "    baseline = 49.9465\n",
    "    focal_length = 641.4094545\n",
    "    \n",
    "    # finding the disparity of each point (and saving x and y points for left image)\n",
    "    disparity = []\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "\n",
    "    for i in range(len(l_saved_points)):\n",
    "        diff = l_saved_points[i][0][0] - r_saved_points[i][0][0]\n",
    "        x = l_saved_points[i][0][0][0]\n",
    "        y = l_saved_points[i][0][0][1]\n",
    "        xdata.append(x)\n",
    "        ydata.append(y)\n",
    "        disparity.append(diff[0])\n",
    "    \n",
    "    # depth (in cm) (if the disparity is closer than 8 pixels we are 2 close to the camera and depth becomes incredibly large so just cap it at 3m)\n",
    "    depth = []\n",
    "    for i in disparity:\n",
    "        i = np.sqrt(i**2)\n",
    "        if i > disp_limit:\n",
    "            d = (baseline*focal_length)/i\n",
    "        else:\n",
    "            d = 3000\n",
    "        depth.append(d)\n",
    "    zdata = depth\n",
    "    \n",
    "    # depth on left image path\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.scatter3D(xdata, ydata, zdata, c=zdata, cmap='jet')\n",
    "    ax.set_xlabel(\"x (pixels)\")\n",
    "    ax.set_ylabel(\"y (pixels)\")\n",
    "    ax.set_zlabel(\"depth (cm)\")\n",
    "\n",
    "    if display == \"base\":\n",
    "        pass\n",
    "    elif display == \"y\":\n",
    "        ax.view_init(0, 0) # y-depth\n",
    "    elif display == \"x\":\n",
    "        ax.view_init(0, 90) # x-depth\n",
    "    elif display == \"xy\":\n",
    "        ax.view_init(90, 90) # y-x\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "    return xdata, ydata, zdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving video with point tracking with depth colour\n",
    "def save_depth_tracking_video(left_array, xdata, ydata, zdata, save_name):\n",
    "    # setting colours based on the depth data\n",
    "    hex_colors = mcp.gen_color_normalized(cmap=\"jet\", data_arr=zdata)\n",
    "    rgb_colors = []\n",
    "    for c in hex_colors:\n",
    "        rgb = PIL.ImageColor.getcolor(c, \"RGB\")\n",
    "        rgb_colors.append(rgb)\n",
    "\n",
    "    # copying array for drawing purposes\n",
    "    left_array_c = left_array.copy()\n",
    "\n",
    "    # image array\n",
    "    limages = []\n",
    "\n",
    "    # creating a mask\n",
    "    maskl = np.zeros_like(left_array_c[0])\n",
    "    imgl = left_array_c[0]\n",
    "\n",
    "    # draw on each frame and save img\n",
    "    for i in range(len(left_array_c)):\n",
    "        maskl = cv2.circle(maskl, (int(xdata[i]), int(ydata[i])), 2, rgb_colors[i], -1)\n",
    "        imgl = cv2.add(left_array_c[i], maskl)\n",
    "        limages.append(imgl)\n",
    "\n",
    "    # save images to npy file \n",
    "    np.save(\"{}.npy\".format(save_name), limages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-vancouver",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_name = 'Stereo_Videos/everywhere_l.mp4'\n",
    "right_name = 'Stereo_Videos/everywhere_r.mp4'\n",
    "left_array, right_array = import_stereo_video(left_name, right_name, start_loss=20, end_loss=20, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_frame1, r_frame1, l_pts, r_pts, l_frame1_gray, r_frame1_gray = find_points(left_array, right_array, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, nadd = find_object_point(491, 1, l_pts, r_pts, l_frame1, r_frame1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_saved_points, r_saved_points, l_saved_imgs, r_saved_imgs, l_mask_imgs, r_mask_imgs = KLT(left_array, right_array, l_frame1, r_frame1, l_frame1_gray, r_frame1_gray, l_pts, r_pts, n, nadd, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata, ydata, zdata = data_3D(l_saved_points, r_saved_points, display=\"base\", disp_limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view same as mask but with depth cmap\n",
    "plt.scatter(xdata, ydata, c=zdata, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_depth_tracking_video(left_array, xdata, ydata, zdata, save_name=\"everywhere-tracked\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
