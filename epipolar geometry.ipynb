{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bronze-firmware",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from numpy.linalg import svd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-hampshire",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Camera parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera baselines (intel realsense D435)\n",
    "HFOV=90 #degrees\n",
    "Xres=848 #pixels\n",
    "baseline=50 #mm\n",
    "f = 0.5*(Xres/np.tan(HFOV/2)) #pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-partnership",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Loading in images and plotting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matching_features(f1, f2, im1, im2):\n",
    "    image1, image2 = im1.copy(), im2.copy()\n",
    "    \n",
    "    for f in f1:\n",
    "        image1 = cv2.circle(image1, (int(f[0]),int(f[1])), 1, (255,255,0), 2)\n",
    "    for f in f2:\n",
    "        image2 = cv2.circle(image2, (int(f[0]),int(f[1])), 1, (255,255,0), 2)\n",
    "        \n",
    "    fig, ax = plt.subplots(1,2, figsize=(15,10))\n",
    "    \n",
    "    ax[0].imshow(image1)\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(\"Left Image\")\n",
    "    ax[1].imshow(image2)\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(\"Right Image\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shift_features(f1,f2,im1):\n",
    "    # from left image we show change to points in right\n",
    "    image1 = im1.copy()\n",
    "    \n",
    "    for l, r in zip(f1, f2):\n",
    "        image1 = cv2.line(image1, (int(l[0]),int(l[1])), (int(r[0]),int(r[1])), (255,0,0), 2)\n",
    "    \n",
    "    plt.figure(figsize=(12,7))\n",
    "    plt.imshow(image1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Change in points from left to right image\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-brown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## SIFT feature finding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matching(img0, img1):\n",
    "    img_1_sift = img0.copy()\n",
    "    img_2_sift = img1.copy()\n",
    "    \n",
    "    img_1_sift = cv2.resize(img_1_sift,(640,480),fx=0,fy=0,interpolation=cv2.INTER_AREA)\n",
    "    img_2_sift = cv2.resize(img_2_sift,(640,480),fx=0,fy=0,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    keypoints_1, descriptors_1 = sift.detectAndCompute(img_1_sift,None)\n",
    "    keypoints_2, descriptors_2 = sift.detectAndCompute(img_2_sift,None)\n",
    "    \n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    \n",
    "    matches = bf.match(descriptors_1, descriptors_2)\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    \n",
    "    features_1 = []\n",
    "    features_2 = []\n",
    "    for i in matches:\n",
    "        features_1.append(keypoints_1[i.queryIdx].pt)\n",
    "        features_2.append(keypoints_2[i.trainIdx].pt)\n",
    "\n",
    "    return features_1, features_2, img_1_sift, img_2_sift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-tournament",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Finding the best F matrix using RANSAC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using ransac to find the best points (and to find the 8 best points that make the best fundamental matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RANSAC_best_Fundamental(img_1_features, img_2_features):\n",
    "   \n",
    "    #RANSAC parameters\n",
    "    N = 2000\n",
    "    sample = 0\n",
    "    thresh = 0.05\n",
    "    inliers_atm = 0\n",
    "    P = 0.99\n",
    "    R_fmat = []\n",
    "\n",
    "    # run loop 2000 times to find the best points\n",
    "    while sample < N:\n",
    "        \n",
    "        rand_p1 = [] ; rand_p2 = []\n",
    "        \n",
    "        # getting a set of random 8 points\n",
    "        index = np.random.randint( len(img_1_features) , size = 8)\n",
    "        \n",
    "        for i in index:\n",
    "            \n",
    "            rand_p1.append(img_1_features[i])\n",
    "            rand_p2.append(img_2_features[i])\n",
    "        \n",
    "        Fundamental = F_matrix(rand_p1, rand_p2)\n",
    "        \n",
    "        # Hartley's 8 points algorithm\n",
    "        ones = np.ones((len(img_1_features),1))\n",
    "        x_1 = np.concatenate((img_1_features,ones),axis=1)\n",
    "        x_2 = np.concatenate((img_2_features,ones),axis=1)\n",
    "        # x_1 and x_2 put it into (x, y, 1) for timsing against F\n",
    "        \n",
    "        # finds error of each point pair and determines if they are inliers or not (the F with most inliers will be kept as the best F matrix)\n",
    "        line_1 = np.dot(x_1, Fundamental.T)\n",
    "        \n",
    "        line_2 = np.dot(x_2,Fundamental)\n",
    "    \n",
    "        e1 = np.sum(line_2* x_1,axis=1,keepdims=True)**2\n",
    "        \n",
    "        e2 = np.sum(np.hstack((line_1[:, :-1],line_2[:,:-1]))**2,axis=1,keepdims=True)\n",
    "        \n",
    "        error =  e1 / e2 \n",
    "        \n",
    "        inliers = error <= thresh\n",
    "         \n",
    "        inlier_count = np.sum(inliers)\n",
    "        \n",
    "        #estimating best Fundamental M\n",
    "        if inliers_atm <  inlier_count:\n",
    "            \n",
    "            inliers_atm = inlier_count\n",
    "            \n",
    "            good_ones = np.where(inliers == True)\n",
    "            \n",
    "            x_1_pts = np.array(img_1_features)\n",
    "            x_2_pts = np.array(img_2_features)\n",
    "            \n",
    "            in_points_x1 = x_1_pts[good_ones[0][:]]\n",
    "            in_points_x2 = x_2_pts[good_ones[0][:]]\n",
    "\n",
    "            R_fmat = Fundamental\n",
    "            \n",
    "        #iterating for N number of times\n",
    "        inlier_ratio = inlier_count/len(img_1_features)\n",
    "        \n",
    "        denominator = np.log(1-(inlier_ratio**8))\n",
    "        \n",
    "        numerator = np.log(1-P)\n",
    "        \n",
    "        if denominator == 0: continue\n",
    "        N =  numerator / denominator\n",
    "        sample += 1\n",
    "        \n",
    "    return R_fmat, in_points_x1, in_points_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_matrix(f1, f2): # takes in 8 feature points from each left and right image and outputs fundamental matrix\n",
    "    \n",
    "    # setting arrays\n",
    "    f1_x = [] ; f1_y = [] ; f2_x = [] ; f2_y = []\n",
    "\n",
    "    f1 = np.asarray(f1)\n",
    "    f2 = np.asarray(f2)\n",
    "\n",
    "    # normalizing features (centereing them at (0,0) and between [-1,1])\n",
    "    # goes under a transformation T: F-hat = T.T^-1*F*T^-1 >>> F = T.T*F-hat*T (have to unnormalize later on)\n",
    "    f1_x_mean = np.mean(f1[:,0])    \n",
    "    f1_y_mean = np.mean(f1[:,1])    \n",
    "    f2_x_mean = np.mean(f2[:,0])        \n",
    "    f2_y_mean = np.mean(f2[:,1])\n",
    "    \n",
    "    # centers values at (0,0)\n",
    "    for i in range(len(f1)): f1[i][0] = f1[i][0] - f1_x_mean\n",
    "    for i in range(len(f1)): f1[i][1] = f1[i][1] - f1_y_mean\n",
    "    for i in range(len(f2)): f2[i][0] = f2[i][0] - f2_x_mean\n",
    "    for i in range(len(f2)): f2[i][1] = f2[i][1] - f2_y_mean\n",
    "\n",
    "    f1_x = np.array(f1[:,0])\n",
    "    f1_y = np.array(f1[:,1])\n",
    "    f2_x = np.array(f2[:,0])\n",
    "    f2_y = np.array(f2[:,1])\n",
    "    \n",
    "    sum_f1 = np.sum((f1)**2, axis = 1)\n",
    "    sum_f2 = np.sum((f2)**2, axis = 1)\n",
    "    \n",
    "    k_1 = np.sqrt(2.)/np.mean(sum_f1**(1/2))\n",
    "    k_2 = np.sqrt(2.)/np.mean(sum_f2**(1/2))\n",
    "\n",
    "    s_f1_1 = np.array([[k_1,0,0],[0,k_1,0],[0,0,1]])\n",
    "    s_f1_2 = np.array([[1,0,-f1_x_mean],[0,1,-f1_y_mean],[0,0,1]])\n",
    "\n",
    "    s_f2_1 = np.array([[k_2,0,0],[0,k_2,0],[0,0,1]])\n",
    "    s_f2_2 = np.array([[1,0,-f2_x_mean],[0,1,-f2_y_mean],[0,0,1]])\n",
    "    \n",
    "    # transformation matrix for unnormalizing later on\n",
    "    t_1 = np.dot(s_f1_1,s_f1_2)\n",
    "    t_2 = np.dot(s_f2_1,s_f2_2)\n",
    "    \n",
    "    # places values between [-1,1]\n",
    "    x1 = ( (f1_x).reshape((-1,1)) ) * k_1\n",
    "    y1 = ( (f1_y).reshape((-1,1)) ) * k_1\n",
    "    x2 = ( (f2_x).reshape((-1,1)) ) * k_2\n",
    "    y2 = ( (f2_y).reshape((-1,1)) ) * k_2\n",
    "    \n",
    "    # creating A using Kronecker product (np.dot(A,F) = 0), which allows us to use an svd to find F\n",
    "    Alist = []\n",
    "    for i in range(x1.shape[0]):\n",
    "        X1, Y1 = x1[i][0],y1[i][0]\n",
    "        X2, Y2 = x2[i][0],y2[i][0]\n",
    "        Alist.append([X2*X1, X2*Y1, X2, Y2*X1, Y2*Y1 , Y2 , X1 , Y1, 1])\n",
    "    A = np.array(Alist) # 8x9 matrix\n",
    "    \n",
    "    # using svd and redoing svd with rank 2 constraint to find F (normalized)\n",
    "    U, sigma, VT = svd(A) # first svd\n",
    "    \n",
    "    f_val = VT.T[:,-1] # grab the last column of V as it is F\n",
    "    f_mat = f_val.reshape((3,3))\n",
    "    \n",
    "    Uf, sigma_f, Vf = np.linalg.svd(f_mat) # redo svd with F\n",
    "    \n",
    "    sigma_f[-1] = 0 # forcing the rank 2 constraint\n",
    "    sigma_final = np.zeros(shape=(3,3)) \n",
    "    sigma_final[0][0] = sigma_f[0] \n",
    "    sigma_final[1][1] = sigma_f[1] \n",
    "    sigma_final[2][2] = sigma_f[2]\n",
    "    \n",
    "    # un-normalizing \n",
    "    f_main = np.dot(Uf , sigma_final)\n",
    "    f_main = np.dot(f_main , Vf)\n",
    "    \n",
    "    f_unnorm = np.dot(t_2.T , f_main)\n",
    "    f_unnorm = np.dot(f_unnorm , t_1)\n",
    "    f_unnorm = f_unnorm/f_unnorm[-1,-1]\n",
    "    \n",
    "    return f_unnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essential matrix using camera calibration matrices cam0 and cam1 and F (I wont use as I havent calibrated camera)\n",
    "def E_matrix(F_matrix):\n",
    "    \n",
    "    e_mat = np.dot(cam1.T,F_matrix)\n",
    "    e_mat = np.dot(e_mat,cam0)\n",
    "    \n",
    "    #solving for E using SVD\n",
    "    Ue, sigma_e, Ve = np.linalg.svd(e_mat)\n",
    "    sigma_final = np.zeros((3,3))\n",
    "    \n",
    "    for i in range(3):\n",
    "        sigma_final[i,i] = 1\n",
    "    sigma_final[-1,-1] = 0\n",
    "\n",
    "    E_mat = np.dot(Ue,sigma_final)\n",
    "    E_mat = np.dot(E_mat,Ve)\n",
    "    \n",
    "    return E_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-optimum",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Finding epipolar lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to draw the epipolar lines on the given images\n",
    "def drawlines(drawline_im1, drawline_im2, lines, pts1, pts2):\n",
    "   \n",
    "    sh = drawline_im1.shape\n",
    "    r = sh[0]\n",
    "    c = sh[1]\n",
    "    \n",
    "    for r, pt1, pt2 in zip(lines,pts1,pts2):\n",
    "        pt1 = [int(pt1[0]),int(pt1[1])]\n",
    "        pt2 = [int(pt2[0]),int(pt2[1])]\n",
    "        \n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        drawline_im1 = cv2.line(drawline_im1, (x0,y0), (x1,y1), color,1)\n",
    "        drawline_im1 = cv2.circle(drawline_im1,tuple(pt1),2,color,-1)\n",
    "        drawline_im2 = cv2.circle(drawline_im2,tuple(pt2),2,color,-1)\n",
    "        \n",
    "    return drawline_im1, drawline_im2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-cosmetic",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Finding 2 homography matrices (left and right image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#least squares technique\n",
    "def least_squares(x_1_ls, x_2_ls):\n",
    "    \n",
    "    lis = list()\n",
    "\n",
    "    #forming the X matrix\n",
    "    X = x_1_ls\n",
    "    Y = np.reshape(x_2_ls, (x_2_ls.shape[0], 1))\n",
    "\n",
    "    #computing B matrix \n",
    "    X_total = np.dot(X.T, X)\n",
    "    X_total_inv = np.linalg.inv(X_total)\n",
    "    Y_total = np.dot(X.T, Y)\n",
    "    B_mat = np.dot(X_total_inv, Y_total)\n",
    "\n",
    "    #computing the y coordinates and forming a list to return\n",
    "    new_y = np.dot(X, B_mat)\n",
    "    for i in new_y:\n",
    "        for a in i:\n",
    "            lis.append(a)\n",
    "\n",
    "    return B_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rectification function to get the homography matrices\n",
    "def to_rectify(F_mat, points1, points2):\n",
    "    \n",
    "    points1 = np.asarray(points1)\n",
    "    points2 = np.asarray(points2)\n",
    "    \n",
    "    # epipoles of left and right images\n",
    "    U, sigma, VT = np.linalg.svd(F_mat)\n",
    "    V = VT.T\n",
    "    s = np.where(sigma < 0.00001)\n",
    "    \n",
    "    e_left = V[:,s[0][0]]\n",
    "    e_right = U[:,s[0][0]]\n",
    "    \n",
    "    e_left = np.reshape(e_left,(e_left.shape[0],1))\n",
    "    e_right = np.reshape(e_right,(e_right.shape[0],1))\n",
    "    \n",
    "    T_1 = np.array([[1,0,-(640/2)],[0,1,-(480/2)],[0,0,1]])\n",
    "    e_final = np.dot(T_1,e_right)\n",
    "    e_final = e_final[:,:]/e_final[-1,:]\n",
    "    \n",
    "    len = ((e_final[0][0])**(2)+(e_final[1][0])**(2))**(1/2)\n",
    "    \n",
    "    if e_final[0][0] >= 0:\n",
    "        \n",
    "        alpha = 1\n",
    "    else:\n",
    "        \n",
    "        alpha = -1\n",
    "        \n",
    "    T_2 = np.array([[(alpha*e_final[0][0])/len, (alpha*e_final[1][0])/len, 0],\n",
    "                    [-(alpha*e_final[1][0])/len, (alpha*e_final[0][0])/len, 0],[0, 0, 1]])\n",
    "    e_final = np.dot(T_2,e_final)\n",
    "    \n",
    "    T_3 = np.array([[1, 0, 0],[0, 1, 0],[((-1)/e_final[0][0]), 0, 1]])\n",
    "    e_final = np.dot(T_3,e_final)\n",
    "    \n",
    "    PHI2 = np.dot(np.dot(np.linalg.inv(T_1),T_3),np.dot(T_2,T_1))\n",
    "\n",
    "    h_ones = np.array([1,1,1])\n",
    "    h_ones = np.reshape(h_ones,(1,3))\n",
    "    \n",
    "    z = np.array([[0,-e_left[2][0],e_left[1][0]],[e_left[2][0],0,\n",
    "                                -e_left[0][0]],[-e_left[1][0],e_left[0][0],0]])\n",
    "    \n",
    "    M = np.dot(z,F_mat) + np.dot(e_left,h_ones)\n",
    "\n",
    "    Homography = np.dot(PHI2,M)\n",
    "    \n",
    "    ones = np.ones((points1.shape[0],1))\n",
    "    points_1 = np.concatenate((points1,ones), axis = 1)\n",
    "    points_2 = np.concatenate((points2,ones), axis = 1)\n",
    "    \n",
    "    x_1 = np.dot(Homography,points_1.T)\n",
    "    x_1 = x_1[:,:]/x_1[2,:]\n",
    "    x_1 = x_1.T\n",
    "    \n",
    "    x_2 = np.dot(PHI2,points_2.T)\n",
    "    x_2 = x_2[:,:]/x_2[2,:]\n",
    "    x_2 = x_2.T\n",
    "    \n",
    "    x_2_dash = np.reshape(x_2[:,0], (x_2.shape[0],1))\n",
    "    \n",
    "    L_S = least_squares(x_1,x_2_dash)\n",
    "    \n",
    "    d_1 = np.array([[L_S[0][0],L_S[1][0],L_S[2][0]],[0,1,0],[0,0,1]])\n",
    "    \n",
    "    PHI1 = np.dot(np.dot(d_1,PHI2),M)\n",
    "    \n",
    "    return PHI1,PHI2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-lease",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Calculate disparity (searching similar pixels points across horizontal lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of absolute difference \n",
    "def s_abs_diff(pixel_vals_1, pixel_vals_2):\n",
    "\n",
    "    if pixel_vals_1.shape != pixel_vals_2.shape:\n",
    "        return -1\n",
    "    return np.sum(abs(pixel_vals_1 - pixel_vals_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare left block of pixels with multiple blocks from the right image using \n",
    "def window_compare(y, x, left_local, right, window_size=5):\n",
    "    \n",
    "    local_window = 20\n",
    "    \n",
    "    # get search range for the right image\n",
    "    x_min = max(0, x - local_window)\n",
    "    x_max = min(right.shape[1], x + local_window)\n",
    "    min_sad = None\n",
    "    index_min = None\n",
    "    first = True\n",
    "    \n",
    "    # only compare to points in the x row as we have reduced search space\n",
    "    for x in range(x_min, x_max):\n",
    "        right_local = right[y: y+window_size,x: x+window_size]\n",
    "        sad = s_abs_diff(left_local, right_local)\n",
    "        if first:\n",
    "            min_sad = sad\n",
    "            index_min = (y, x)\n",
    "            first = False\n",
    "        else:\n",
    "            if sad < min_sad:\n",
    "                min_sad = sad\n",
    "                index_min = (y, x)\n",
    "\n",
    "    return index_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disparity calculation on the recified images\n",
    "def disparity_calc(image_left, image_right):\n",
    "    \n",
    "    window = 5\n",
    "\n",
    "    left = np.asarray(image_left)\n",
    "    right = np.asarray(image_right)\n",
    "    \n",
    "    left = left.astype(int)\n",
    "    right = right.astype(int)\n",
    "    \n",
    "    if left.shape != right.shape:\n",
    "        print(\"Image Shapes do not match!!\")\n",
    "      \n",
    "    h, w, g = left.shape\n",
    "    \n",
    "    disparity = np.zeros((h, w))\n",
    "    # going over each pixel\n",
    "    for y in range(window, h-window):\n",
    "        for x in range(window, w-window):\n",
    "            left_local = left[y:y + window, x:x + window]\n",
    "            index_min = window_compare(y, x, left_local, right, window_size = window)\n",
    "            disparity[y, x] = abs(index_min[1] - x)\n",
    "            \n",
    "    plt.imshow(disparity, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title('Disparity Plot Heat')\n",
    "    plt.show()\n",
    "    \n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-villa",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Calculate depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images in (left and right)\n",
    "i = 114\n",
    "img0 = cv2.imread(\"Images/Image{}.png\".format(i+1))\n",
    "img1 = cv2.imread(\"Images/Image{}.png\".format(i))\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,7))\n",
    "ax[0].imshow(img0)\n",
    "ax[0].set_title(\"Original Left Image\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(img1)\n",
    "ax[1].set_title(\"Original Right Image\")\n",
    "ax[1].axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# find SIFT features\n",
    "print(\"Finding SIFT features:\")\n",
    "f1, f2, im1, im2 = feature_matching(img0, img1)\n",
    "plot_matching_features(f1,f2,im1,im2)\n",
    "plot_shift_features(f1,f2,im1)\n",
    "\n",
    "# copy images for drawing on\n",
    "img_1_copy1 = im1.copy()\n",
    "img_2_copy1 = im2.copy()\n",
    "\n",
    "# remove outliers and solve F matrix\n",
    "print(\"Removing outlier features with RANSAC:\")\n",
    "best_f_matrix, r_points_1, r_points_2 = RANSAC_best_Fundamental(f1, f2)\n",
    "plot_matching_features(r_points_1,r_points_2,im1,im2)\n",
    "plot_shift_features(r_points_1,r_points_2,im1)\n",
    "\n",
    "# compute and draw epipolar lines\n",
    "print(\"Computing Epipolar lines:\")\n",
    "epilines_1 = cv2.computeCorrespondEpilines(r_points_2.reshape(-1,1,2), 2, best_f_matrix)\n",
    "epilines_1 = epilines_1.reshape(-1,3)\n",
    "\n",
    "epilines_2 = cv2.computeCorrespondEpilines(r_points_1.reshape(-1,1,2), 1,best_f_matrix)\n",
    "epilines_2 = epilines_2.reshape(-1,3)\n",
    "\n",
    "im1, im2 = drawlines(im1, im2, epilines_1, r_points_1[:100], r_points_2[:100])\n",
    "im1, im2 = drawlines(im2, im1, epilines_2, r_points_1[:100], r_points_2[:100])\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,7))\n",
    "ax[0].imshow(im1)\n",
    "ax[0].set_title(\"Left Image\")\n",
    "ax[1].imshow(im2)\n",
    "ax[1].set_title(\"Right Image\")\n",
    "plt.show()\n",
    "\n",
    "# putting points into (x, y, 1) form\n",
    "one_s = np.ones((r_points_1.shape[0],1))\n",
    "r_points_1 = np.concatenate((r_points_1,one_s),axis = 1)\n",
    "r_points_2 = np.concatenate((r_points_2,one_s),axis = 1)\n",
    "\n",
    "# computing homography: I dont reaaly understand what they did in this section to find the 2 homography matrices\n",
    "print(\"Computing Homography matrix for warping images:\")\n",
    "Hom_0 , Hom_1 = to_rectify(best_f_matrix, f1, f2)\n",
    "print('Homography Mat 1 : \\n', Hom_0)\n",
    "print('\\nHomography Mat 2 : \\n', Hom_1)\n",
    "\n",
    "# warp images based off homography matrices: new img1 coords = H1 x (old img1 coords)\n",
    "print(\"Perspective Warping Images:\")\n",
    "left_rectified = cv2.warpPerspective(im1, Hom_0, (640,480))\n",
    "right_rectified = cv2.warpPerspective(im2, Hom_1, (640,480))\n",
    "\n",
    "left_rec_nolines = cv2.warpPerspective(img_1_copy1, Hom_0, (640,480))\n",
    "right_rec_nolines = cv2.warpPerspective(img_2_copy1, Hom_1, (640,480))\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,7))\n",
    "ax[0].imshow(left_rectified)\n",
    "ax[0].set_title(\"Left Rectified Image\")\n",
    "ax[1].imshow(right_rectified)\n",
    "ax[1].set_title(\"Right Rectified Image\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,7))\n",
    "ax[0].imshow(left_rec_nolines)\n",
    "ax[0].set_title(\"Left Rectified Image\")\n",
    "ax[1].imshow(right_rec_nolines)\n",
    "ax[1].set_title(\"Right Rectified Image\")\n",
    "plt.show()\n",
    "\n",
    "# calc disparity\n",
    "print(\"Calculating Disparity:\")\n",
    "disparity = disparity_calc(left_rec_nolines, right_rec_nolines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = disparity.copy()\n",
    "\n",
    "# to stop disp = 0 (cant divide by 0)\n",
    "disp[disp==0] = 10\n",
    "\n",
    "depth = baseline * f / disp\n",
    "\n",
    "# depth is in mm (change to m)\n",
    "depth = depth/(1000)\n",
    "\n",
    "plt.imshow(depth, cmap='gray', interpolation='bilinear')\n",
    "plt.title('Depth Plot Gray')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(depth, cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.title('Depth Plot Heat (meters)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-daisy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
