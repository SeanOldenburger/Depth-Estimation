{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "administrative-breed",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "from Superstuff.matching import Matching\n",
    "import Superstuff.utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-cabinet",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## cv2 implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images in (left and right) # 0 -> 2 (bottle + pages) or 122 -> 126 (book + pages) or 82 -> 86 (bottle) or 66 -> 70 (mustache)\n",
    "i = 335\n",
    "imgR = cv2.imread(\"Better_Images/Image{}.png\".format(i+1))\n",
    "imgL = cv2.imread(\"Better_Images/Image{}.png\".format(i))\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,7))\n",
    "ax[0].imshow(imgL)\n",
    "ax[0].set_title(\"Original Left Image\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(imgR)\n",
    "ax[1].set_title(\"Original Right Image\")\n",
    "ax[1].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters for StereoSGBM algorithm\n",
    "minDisparity = 0\n",
    "numDisparities = 100\n",
    "blockSize = 15\n",
    "disp12MaxDiff = 1\n",
    "uniquenessRatio = 5\n",
    "speckleWindowSize = 15\n",
    "speckleRange = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an object of StereoSGBM algorithm ()\n",
    "stereo = cv2.StereoSGBM_create(minDisparity = minDisparity,\n",
    "        numDisparities = numDisparities,\n",
    "        blockSize = blockSize,\n",
    "        disp12MaxDiff = disp12MaxDiff,\n",
    "        uniquenessRatio = uniquenessRatio,\n",
    "        speckleWindowSize = speckleWindowSize,\n",
    "        speckleRange = speckleRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating disparith using the StereoSGBM algorithm\n",
    "disp = stereo.compute(imgL, imgR).astype(np.float32)\n",
    "disp = cv2.normalize(disp,0,255,cv2.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the disparity map\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "plt.imshow(disp)\n",
    "plt.colorbar()\n",
    "ax.imshow(disp)\n",
    "ax.set_title(\"Disparity\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-sound",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## My implementation -> their disparity computation + rectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matching_features(f1, f2, im1, im2):\n",
    "    image1, image2 = im1.copy(), im2.copy()\n",
    "    \n",
    "    for f in f1:\n",
    "        image1 = cv2.circle(image1, (int(f[0]),int(f[1])), 1, (255,255,0), 2)\n",
    "    for f in f2:\n",
    "        image2 = cv2.circle(image2, (int(f[0]),int(f[1])), 1, (255,255,0), 2)\n",
    "        \n",
    "    fig, ax = plt.subplots(1,2, figsize=(15,10))\n",
    "    \n",
    "    ax[0].imshow(image1)\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(\"Left Image\")\n",
    "    ax[1].imshow(image2)\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(\"Right Image\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_shift_features(f1,f2,im1):\n",
    "    # from left image we show change to points in right\n",
    "    image1 = im1.copy()\n",
    "    \n",
    "    for l, r in zip(f1, f2):\n",
    "        image1 = cv2.line(image1, (int(l[0]),int(l[1])), (int(r[0]),int(r[1])), (255,0,0), 2)\n",
    "    \n",
    "    plt.figure(figsize=(12,7))\n",
    "    plt.imshow(image1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Change in points from left to right image\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(imgL,None)\n",
    "kp2, des2 = sift.detectAndCompute(imgR,None)\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "\n",
    "# ratio test as per Lowe's paper\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.8*n.distance:\n",
    "        pts2.append(kp2[m.trainIdx].pt)\n",
    "        pts1.append(kp1[m.queryIdx].pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matching_features(pts1, pts2, imgL, imgR)\n",
    "plot_shift_features(pts1,pts2,imgL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1 = np.int32(pts1)\n",
    "pts2 = np.int32(pts2)\n",
    "\n",
    "F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_LMEDS)\n",
    "\n",
    "# We select only inlier points\n",
    "pts1 = pts1[mask.ravel()==1]\n",
    "pts2 = pts2[mask.ravel()==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matching_features(pts1, pts2, imgL, imgR)\n",
    "plot_shift_features(pts1,pts2,imgL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    r,c,w = img1.shape\n",
    "    #img1 = cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\n",
    "    #img2 = cv2.cvtColor(img2,cv2.COLOR_GRAY2BGR)\n",
    "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = cv2.line(img1, (x0,y0), (x1,y1), color,1)\n",
    "        img1 = cv2.circle(img1,tuple(pt1),5,color,-1)\n",
    "        img2 = cv2.circle(img2,tuple(pt2),5,color,-1)\n",
    "    return img1,img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find epilines corresponding to points in right image (second image) and\n",
    "# drawing its lines on left image\n",
    "lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n",
    "lines1 = lines1.reshape(-1,3)\n",
    "img5,img6 = drawlines(imgL,imgR,lines1,pts1,pts2)\n",
    "\n",
    "# Find epilines corresponding to points in left image (first image) and\n",
    "# drawing its lines on right image\n",
    "lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n",
    "lines2 = lines2.reshape(-1,3)\n",
    "img3,img4 = drawlines(imgL,imgR,lines2,pts2,pts1)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,10))\n",
    "\n",
    "ax[0].imshow(img5)\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"Left Image\")\n",
    "ax[1].imshow(img3)\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(\"Right Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "retval, H1, H2 = cv2.stereoRectifyUncalibrated(points1=pts1, points2=pts2, F=F, imgSize=(1280,720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warp images based off homography matrices: new img1 coords = H1 x (old img1 coords)\n",
    "print(\"Perspective Warping Images:\")\n",
    "left_rectified = cv2.warpPerspective(img5, H1, (1280,720))\n",
    "right_rectified = cv2.warpPerspective(img3, H2, (1280,720))\n",
    "\n",
    "left_rec_nolines = cv2.warpPerspective(imgL, H1, (1280,720))\n",
    "right_rec_nolines = cv2.warpPerspective(imgR, H2, (1280,720))\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,7))\n",
    "ax[0].imshow(left_rectified)\n",
    "ax[0].set_title(\"Left Rectified Image\")\n",
    "ax[1].imshow(right_rectified)\n",
    "ax[1].set_title(\"Right Rectified Image\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,7))\n",
    "ax[0].imshow(left_rec_nolines)\n",
    "ax[0].set_title(\"Left Rectified Image\")\n",
    "ax[1].imshow(right_rec_nolines)\n",
    "ax[1].set_title(\"Right Rectified Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating disparith using the StereoSGBM algorithm\n",
    "disp3 = stereo.compute(left_rec_nolines, right_rec_nolines).astype(np.float32)\n",
    "disp3 = cv2.normalize(disp3,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Displaying the disparity map\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "plt.imshow(disp3)\n",
    "plt.colorbar()\n",
    "ax.imshow(disp3)\n",
    "ax.set_title(\"Disparity\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-virtue",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## My implementation -> my disparity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of absolute difference \n",
    "def s_abs_diff(pixel_vals_1, pixel_vals_2):\n",
    "\n",
    "    if pixel_vals_1.shape != pixel_vals_2.shape:\n",
    "        return -1\n",
    "    return np.sum(abs(pixel_vals_1 - pixel_vals_2))\n",
    "\n",
    "# compare left block of pixels with multiple blocks from the right image using \n",
    "def window_compare(y, x, left_local, right, window_size=5):\n",
    "    \n",
    "    local_window = 100\n",
    "    \n",
    "    # get search range for the right image\n",
    "    x_min = max(0, x - local_window)\n",
    "    x_max = min(right.shape[1], x + local_window)\n",
    "    min_sad = None\n",
    "    index_min = None\n",
    "    first = True\n",
    "    \n",
    "    # only compare to points in the x row as we have reduced search space\n",
    "    for x in range(x_min, x_max):\n",
    "        right_local = right[y: y+window_size,x: x+window_size]\n",
    "        sad = s_abs_diff(left_local, right_local)\n",
    "        if first:\n",
    "            min_sad = sad\n",
    "            index_min = (y, x)\n",
    "            first = False\n",
    "        else:\n",
    "            if sad < min_sad:\n",
    "                min_sad = sad\n",
    "                index_min = (y, x)\n",
    "\n",
    "    return index_min\n",
    "\n",
    "#disparity calculation on the recified images\n",
    "def disparity_calc(image_left, image_right):\n",
    "    \n",
    "    window = 5\n",
    "\n",
    "    left = np.asarray(image_left)\n",
    "    right = np.asarray(image_right)\n",
    "    \n",
    "    left = left.astype(int)\n",
    "    right = right.astype(int)\n",
    "    \n",
    "    if left.shape != right.shape:\n",
    "        print(\"Image Shapes do not match!!\")\n",
    "      \n",
    "    h, w, g = left.shape\n",
    "    \n",
    "    disparity = np.zeros((h, w))\n",
    "    # going over each pixel\n",
    "    for y in range(window, h-window):\n",
    "        for x in range(window, w-window):\n",
    "            left_local = left[y:y + window, x:x + window]\n",
    "            index_min = window_compare(y, x, left_local, right, window_size = window)\n",
    "            disparity[y, x] = abs(index_min[1] - x)\n",
    "            \n",
    "    plt.imshow(disparity, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title('Disparity Plot Heat')\n",
    "    plt.show()\n",
    "    \n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity = disparity_calc(left_rec_nolines, right_rec_nolines)\n",
    "disparity = cv2.normalize(disparity,0,255,cv2.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the disparity map\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "plt.imshow(disparity)\n",
    "plt.colorbar()\n",
    "ax.imshow(disparity)\n",
    "ax.set_title(\"Disparity\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-cassette",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## someone elses code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_number = 0\n",
    "imgR = cv2.imread(\"3D_images/ImagePair{}-{}.png\".format(pair_number, 1))\n",
    "imgL = cv2.imread(\"3D_images/ImagePair{}-{}.png\".format(pair_number, 0))\n",
    "real_depth = cv2.imread(\"3D_images/ImagePair{}-{}.png\".format(pair_number, 2))\n",
    "col_img = cv2.imread(\"3D_images/ImagePair{}-{}.png\".format(pair_number, 3))\n",
    "col_img = cv2.cvtColor(col_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, ax = plt.subplots(1,4,figsize=(20,10))\n",
    "ax[0].imshow(imgL)\n",
    "ax[0].set_title(\"Original Left Image\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(imgR)\n",
    "ax[1].set_title(\"Original Right Image\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[2].imshow(real_depth)\n",
    "ax[2].set_title(\"Real Depth\")\n",
    "ax[2].axis(\"off\")\n",
    "ax[3].imshow(col_img)\n",
    "ax[3].set_title(\"Colour Image\")\n",
    "ax[3].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgL_c = imgL.copy()\n",
    "imgR_c = imgR.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(imgL, None)\n",
    "kp2, des2 = sift.detectAndCompute(imgR, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize keypoints\n",
    "imgSift = cv2.drawKeypoints(imgL, kp1, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.imshow(imgSift)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match keypoints in both images\n",
    "# Based on: https://docs.opencv.org/master/dc/dc3/tutorial_py_matcher.html\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Keep good matches: calculate distinctive image features\n",
    "# Lowe, D.G. Distinctive Image Features from Scale-Invariant Keypoints. International Journal of Computer Vision 60, 91â€“110 (2004). https://doi.org/10.1023/B:VISI.0000029664.99615.94\n",
    "# https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\n",
    "matchesMask = [[0, 0] for i in range(len(matches))]\n",
    "good = []\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "\n",
    "for i, (m, n) in enumerate(matches):\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        # Keep this keypoint pair\n",
    "        matchesMask[i] = [1, 0]\n",
    "        good.append(m)\n",
    "        pts2.append(kp2[m.trainIdx].pt)\n",
    "        pts1.append(kp1[m.queryIdx].pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the keypoint matches between both pictures\n",
    "# Still based on: https://docs.opencv.org/master/dc/dc3/tutorial_py_matcher.html\n",
    "draw_params = dict(matchColor=(0, 255, 0),\n",
    "                   singlePointColor=(255, 0, 0),\n",
    "                   matchesMask=matchesMask[300:500],\n",
    "                   flags=cv2.DrawMatchesFlags_DEFAULT)\n",
    "\n",
    "keypoint_matches = cv2.drawMatchesKnn(\n",
    "    imgL, kp1, imgR, kp2, matches[200:400], None, **draw_params)\n",
    "plt.imshow(keypoint_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the fundamental matrix for the cameras\n",
    "# https://docs.opencv.org/master/da/de9/tutorial_py_epipolar_geometry.html\n",
    "pts1 = np.int32(pts1)\n",
    "pts2 = np.int32(pts2)\n",
    "fundamental_matrix, inliers = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC)\n",
    "\n",
    "# We select only inlier points\n",
    "pts1 = pts1[inliers.ravel() == 1]\n",
    "pts2 = pts2[inliers.ravel() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize epilines\n",
    "# Adapted from: https://docs.opencv.org/master/da/de9/tutorial_py_epipolar_geometry.html\n",
    "def drawlines(img1src, img2src, lines, pts1src, pts2src):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    r, c, h = img1src.shape\n",
    "    #img1color = cv2.cvtColor(img1src, cv2.COLOR_GRAY2BGR)\n",
    "    #img2color = cv2.cvtColor(img2src, cv2.COLOR_GRAY2BGR)\n",
    "    # Edit: use the same random seed so that two images are comparable!\n",
    "    np.random.seed(0)\n",
    "    for r, pt1, pt2 in zip(lines, pts1src, pts2src):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        x0, y0 = map(int, [0, -r[2]/r[1]])\n",
    "        x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])\n",
    "        img1color = cv2.line(img1src, (x0, y0), (x1, y1), color, 1)\n",
    "        img1color = cv2.circle(img1src, tuple(pt1), 5, color, -1)\n",
    "        img2color = cv2.circle(img2src, tuple(pt2), 5, color, -1)\n",
    "    return img1color, img2color\n",
    "\n",
    "\n",
    "# Find epilines corresponding to points in right image (second image) and\n",
    "# drawing its lines on left image\n",
    "lines1 = cv2.computeCorrespondEpilines(\n",
    "    pts2.reshape(-1, 1, 2), 2, fundamental_matrix)\n",
    "lines1 = lines1.reshape(-1, 3)\n",
    "img5, img6 = drawlines(imgL, imgR, lines1, pts1, pts2)\n",
    "\n",
    "# Find epilines corresponding to points in left image (first image) and\n",
    "# drawing its lines on right image\n",
    "lines2 = cv2.computeCorrespondEpilines(\n",
    "    pts1.reshape(-1, 1, 2), 1, fundamental_matrix)\n",
    "lines2 = lines2.reshape(-1, 3)\n",
    "img3, img4 = drawlines(imgR, imgL, lines2, pts2, pts1)\n",
    "\n",
    "plt.subplot(121), plt.imshow(img5)\n",
    "plt.subplot(122), plt.imshow(img3)\n",
    "plt.suptitle(\"Epilines in both images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stereo rectification (uncalibrated variant)\n",
    "# Adapted from: https://stackoverflow.com/a/62607343\n",
    "h1, w1, z1 = imgL.shape\n",
    "h2, w2, z2 = imgR.shape\n",
    "_, H1, H2 = cv2.stereoRectifyUncalibrated(\n",
    "    np.float32(pts1), np.float32(pts2), fundamental_matrix, imgSize=(w1, h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undistort (rectify) the images and save them\n",
    "# Adapted from: https://stackoverflow.com/a/62607343\n",
    "img1_rectified = cv2.warpPerspective(imgL, H1, (w1, h1))\n",
    "img2_rectified = cv2.warpPerspective(imgR, H2, (w2, h2))\n",
    "\n",
    "img1_rectified_clean = cv2.warpPerspective(imgL_c, H1, (w1, h1))\n",
    "img2_rectified_clean = cv2.warpPerspective(imgR_c, H2, (w2, h2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the rectified images\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes[0, 0].imshow(img1_rectified, cmap=\"gray\")\n",
    "axes[0, 1].imshow(img2_rectified, cmap=\"gray\")\n",
    "axes[1, 0].imshow(img1_rectified_clean, cmap=\"gray\")\n",
    "axes[1, 1].imshow(img2_rectified_clean, cmap=\"gray\")\n",
    "plt.suptitle(\"Rectified images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matched block size. It must be an odd number >=1 . Normally, it should be somewhere in the 3..11 range.\n",
    "block_size = 10\n",
    "min_disp = -64\n",
    "max_disp = 64\n",
    "# Maximum disparity minus minimum disparity. The value is always greater than zero.\n",
    "# In the current implementation, this parameter must be divisible by 16.\n",
    "num_disp = max_disp - min_disp\n",
    "# Margin in percentage by which the best (minimum) computed cost function value should \"win\" the second best value to consider the found match correct.\n",
    "# Normally, a value within the 5-15 range is good enough\n",
    "uniquenessRatio = 5\n",
    "# Maximum size of smooth disparity regions to consider their noise speckles and invalidate.\n",
    "# Set it to 0 to disable speckle filtering. Otherwise, set it somewhere in the 50-200 range.\n",
    "speckleWindowSize = 200\n",
    "# Maximum disparity variation within each connected component.\n",
    "# If you do speckle filtering, set the parameter to a positive value, it will be implicitly multiplied by 16.\n",
    "# Normally, 1 or 2 is good enough.\n",
    "speckleRange = 2\n",
    "disp12MaxDiff = 0\n",
    "\n",
    "left_matcher = cv2.StereoSGBM_create(\n",
    "    minDisparity=min_disp,\n",
    "    numDisparities=num_disp,\n",
    "    blockSize=block_size,\n",
    "    uniquenessRatio=uniquenessRatio,\n",
    "    speckleWindowSize=speckleWindowSize,\n",
    "    speckleRange=speckleRange,\n",
    "    disp12MaxDiff=disp12MaxDiff,\n",
    "    P1=8 * 1 * block_size * block_size,\n",
    "    P2=32 * 1 * block_size * block_size,\n",
    ")\n",
    "\n",
    "right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "\n",
    "grayLeft = cv2.cvtColor(img1_rectified_clean, cv2.COLOR_BGR2GRAY)\n",
    "grayRight = cv2.cvtColor(img2_rectified_clean, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "left_disp = left_matcher.compute(grayLeft, grayRight)\n",
    "right_disp = right_matcher.compute(grayRight, grayLeft)\n",
    "\n",
    "sigma = 10\n",
    "lmbda = 10\n",
    "wls_filter = cv2.ximgproc.createDisparityWLSFilter(left_matcher)\n",
    "wls_filter.setLambda(lmbda)\n",
    "wls_filter.setSigmaColor(sigma)\n",
    "filtered_disp = wls_filter.filter(left_disp, grayLeft, disparity_map_right=right_disp)\n",
    "\n",
    "# Displaying the disparity map\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.imshow(filtered_disp, cmap='jet')\n",
    "plt.colorbar()\n",
    "ax.imshow(filtered_disp, cmap='jet')\n",
    "ax.set_title(\"Disparity\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayLeft_c = cv2.cvtColor(imgL_c, cv2.COLOR_BGR2GRAY)\n",
    "grayRight_c = cv2.cvtColor(imgR_c, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "left_disp = left_matcher.compute(grayLeft_c, grayRight_c)\n",
    "right_disp = right_matcher.compute(grayRight_c, grayLeft_c)\n",
    "\n",
    "sigma = 4\n",
    "lmbda = 100\n",
    "wls_filter = cv2.ximgproc.createDisparityWLSFilter(left_matcher)\n",
    "wls_filter.setLambda(lmbda)\n",
    "wls_filter.setSigmaColor(sigma)\n",
    "filtered_disp = wls_filter.filter(left_disp, grayLeft_c, disparity_map_right=right_disp)\n",
    "\n",
    "# Displaying the disparity map\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.imshow(filtered_disp, cmap='jet')\n",
    "plt.colorbar()\n",
    "ax.imshow(filtered_disp, cmap='jet')\n",
    "ax.set_title(\"Disparity\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
