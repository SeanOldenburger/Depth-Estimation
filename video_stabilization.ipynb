{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "velvet-fever",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "from IPython. display import clear_output\n",
    "import time\n",
    "from mycolorpy import colorlist as mcp\n",
    "import PIL\n",
    "from Superstuff.matching import Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-representative",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matching_plot_fast(image0, image1, kpts0, kpts1, mkpts0,\n",
    "                            mkpts1, color, text, path=None,\n",
    "                            show_keypoints=False, margin=10,\n",
    "                            opencv_display=False, opencv_title='',\n",
    "                            small_text=[]):\n",
    "    H0, W0 = image0.shape\n",
    "    H1, W1 = image1.shape\n",
    "    H, W = max(H0, H1), W0 + W1 + margin\n",
    "\n",
    "    out = 255*np.ones((H, W), np.uint8)\n",
    "    out[:H0, :W0] = image0\n",
    "    out[:H1, W0+margin:] = image1\n",
    "    out = np.stack([out]*3, -1)\n",
    "\n",
    "    if show_keypoints:\n",
    "        kpts0, kpts1 = np.round(kpts0).astype(int), np.round(kpts1).astype(int)\n",
    "        white = (255, 255, 255)\n",
    "        black = (0, 0, 0)\n",
    "        for x, y in kpts0:\n",
    "            cv2.circle(out, (x, y), 2, black, -1, lineType=cv2.LINE_AA)\n",
    "            cv2.circle(out, (x, y), 1, white, -1, lineType=cv2.LINE_AA)\n",
    "        for x, y in kpts1:\n",
    "            cv2.circle(out, (x + margin + W0, y), 2, black, -1,\n",
    "                       lineType=cv2.LINE_AA)\n",
    "            cv2.circle(out, (x + margin + W0, y), 1, white, -1,\n",
    "                       lineType=cv2.LINE_AA)\n",
    "\n",
    "    mkpts0, mkpts1 = np.round(mkpts0).astype(int), np.round(mkpts1).astype(int)\n",
    "    color = (np.array(color[:, :3])*255).astype(int)[:, ::-1]\n",
    "    for (x0, y0), (x1, y1), c in zip(mkpts0, mkpts1, color):\n",
    "        c = c.tolist()\n",
    "        cv2.line(out, (x0, y0), (x1 + margin + W0, y1),\n",
    "                 color=c, thickness=1, lineType=cv2.LINE_AA)\n",
    "        # display line end-points as circles\n",
    "        cv2.circle(out, (x0, y0), 2, c, -1, lineType=cv2.LINE_AA)\n",
    "        cv2.circle(out, (x1 + margin + W0, y1), 2, c, -1,\n",
    "                   lineType=cv2.LINE_AA)\n",
    "\n",
    "    # Scale factor for consistent visualization across scales.\n",
    "    sc = min(H / 640., 2.0)\n",
    "\n",
    "    # Big text.\n",
    "    Ht = int(30 * sc)  # text height\n",
    "    txt_color_fg = (255, 255, 255)\n",
    "    txt_color_bg = (0, 0, 0)\n",
    "    for i, t in enumerate(text):\n",
    "        cv2.putText(out, t, (int(8*sc), Ht*(i+1)), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    1.0*sc, txt_color_bg, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, t, (int(8*sc), Ht*(i+1)), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    1.0*sc, txt_color_fg, 1, cv2.LINE_AA)\n",
    "\n",
    "    # Small text.\n",
    "    Ht = int(18 * sc)  # text height\n",
    "    for i, t in enumerate(reversed(small_text)):\n",
    "        cv2.putText(out, t, (int(8*sc), int(H-Ht*(i+.6))), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    0.5*sc, txt_color_bg, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, t, (int(8*sc), int(H-Ht*(i+.6))), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    0.5*sc, txt_color_fg, 1, cv2.LINE_AA)\n",
    "\n",
    "    if path is not None:\n",
    "        cv2.imwrite(str(path), out)\n",
    "\n",
    "    if opencv_display:\n",
    "        cv2.imshow(opencv_title, out)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    ax.imshow(out)\n",
    "    ax.set_title(opencv_title)\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_points(matcher, l_frame1, r_frame1, display=True):\n",
    "    # convert to tensor\n",
    "    # set first frame and first points for left and right\n",
    "    #l_frame1_gray = cv2.cvtColor(l_frame1, cv2.COLOR_RGB2GRAY)\n",
    "    l_frame1_gray_t = torch.from_numpy(l_frame1/255.).float()[None, None]\n",
    "\n",
    "    #r_frame1_gray = cv2.cvtColor(r_frame1, cv2.COLOR_RGB2GRAY)\n",
    "    r_frame1_gray_t = torch.from_numpy(r_frame1/255.).float()[None, None]\n",
    "    \n",
    "    # finding matching points in first frame for l and r\n",
    "    pred = matcher({'image0': l_frame1_gray_t, 'image1': r_frame1_gray_t})\n",
    "\n",
    "    # get sections from output (pred)\n",
    "    l_kp = pred['keypoints0'][0].cpu().numpy()\n",
    "    r_kp = pred['keypoints1'][0].cpu().numpy()\n",
    "    matches = pred['matches0'][0].cpu().numpy()\n",
    "    confidence = pred['matching_scores0'][0].detach().cpu().numpy()\n",
    "\n",
    "    # keep only the valid matches and make points from found kp\n",
    "    valid = matches > -1\n",
    "    l_pts = l_kp[valid]\n",
    "    r_pts = r_kp[matches[valid]]\n",
    "\n",
    "    # plot kp and matches betwwen 2 images\n",
    "    color = cm.jet(confidence[valid])\n",
    "    text = ['SuperGlue',\n",
    "        'Keypoints: {}:{}'.format(len(l_kp), len(r_kp)),\n",
    "        'Matches: {}'.format(len(l_pts))]\n",
    "    \n",
    "    # view matches found\n",
    "    if display:\n",
    "        out = make_matching_plot_fast(\n",
    "                    l_frame1, r_frame1, l_kp, r_kp, l_pts, r_pts, color, text,\n",
    "                    path=None, show_keypoints=True)\n",
    "    \n",
    "    return l_frame1, r_frame1, l_pts, r_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_object_point(n, nadd, l_pts, r_pts, l_frame1, r_frame1):\n",
    "    # Create some random colors (100 of them)\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    # copies for drawing on\n",
    "    left_c = l_frame1.copy()\n",
    "    right_c = r_frame1.copy()\n",
    "\n",
    "    # left drawing\n",
    "    for i in l_pts[n:n+nadd]:\n",
    "        pointl = (i[0].astype(int), i[1].astype(int))\n",
    "        left_c = cv2.circle(left_c, pointl, 2, (255,0,0), -1)\n",
    "\n",
    "    # right drawing\n",
    "    for i in r_pts[n:n+nadd]:\n",
    "        pointr = (i[0].astype(int), i[1].astype(int))\n",
    "        right_c = cv2.circle(right_c, pointr, 2, (255,0,0), -1)\n",
    "\n",
    "    # plot left and right\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    ax.imshow(np.hstack([left_c, right_c]))\n",
    "    ax.set_title('Left -> Right')\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    return n, nadd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_3D_revised(l_saved_point, r_saved_point, display='base'):\n",
    "    # camera baselines\n",
    "    b = 49.9465\n",
    "    f = 1.93\n",
    "    \n",
    "    zdata = []\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    \n",
    "    for i in range(len(l_saved_point)):\n",
    "        x1 = l_saved_point[i][0]\n",
    "        x2 = r_saved_point[i][0]\n",
    "\n",
    "        z = (b*f*190)/(np.sqrt((x1-x2)**2))\n",
    "        \n",
    "        zdata.append(z)\n",
    "    \n",
    "    # use only the left frame to find x and y over frames\n",
    "    for i in range(len(l_saved_point)):\n",
    "        x1 = l_saved_point[i][0]\n",
    "        y1 = l_saved_point[i][1]\n",
    "        \n",
    "        # distance from 0 point\n",
    "        x2 = 0\n",
    "        y2 = 0\n",
    "        \n",
    "        z = zdata[i]\n",
    "        \n",
    "        x = ((x1-x2)/(f*210))*z\n",
    "        y = ((y1-y2)/(f*210))*z\n",
    "        \n",
    "        xdata.append(x)\n",
    "        ydata.append(y)\n",
    "    \n",
    "    return xdata, ydata, zdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_stereo_video(left_name, right_name, start_loss=20, end_loss=20, display=True, only_left=False):\n",
    "    # load in video file\n",
    "    left_vid = cv2.VideoCapture(left_name)\n",
    "    right_vid = cv2.VideoCapture(right_name)\n",
    "    \n",
    "    # print some specs\n",
    "    fps = right_vid.get(5)\n",
    "    frame_count = right_vid.get(7)\n",
    "    print(\"Loaded in video:\\nFPS: {} \\tFrame Count: {}\".format(int(fps), int(frame_count)-end_loss-start_loss))\n",
    "    \n",
    "    # convert to arrays\n",
    "    left_array = []\n",
    "    ret = True\n",
    "    while ret == True:\n",
    "        ret, frame = left_vid.read()\n",
    "        if frame is not None:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            left_array.append(frame)\n",
    "    left_array = np.array(left_array)\n",
    "    left_array = left_array[start_loss:-end_loss]\n",
    "    print(\"Left Array Loaded  | Size: {}\".format(left_array.shape))\n",
    "\n",
    "    right_array = []\n",
    "    if only_left == False:\n",
    "        ret = True\n",
    "        while ret == True:\n",
    "            ret, frame = right_vid.read()\n",
    "            if frame is not None:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                right_array.append(frame)\n",
    "        right_array = np.array(right_array)\n",
    "        right_array = right_array[start_loss:-end_loss]\n",
    "        print(\"Right Array Loaded | Size: {}\".format(left_array.shape))\n",
    "    \n",
    "    if display:\n",
    "        plt.imshow(left_array[0])\n",
    "        plt.title(\"First Frame:\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    \n",
    "    return left_array, right_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-dakota",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Load video in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera rotation translation stuff\n",
    "# camera matrix and distortion for 640x480 res: \n",
    "camera_matrix = np.array([[382.63, 0, 321.202],[0, 382.63, 239.855],[0, 0, 1]])\n",
    "distortion =  np.array([-0.055629, 0.063853, -0.000203, -0.000965, -0.020792])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in video array:\n",
    "left_name = 'stabilization_videos/vid3.mp4'\n",
    "right_name = 'stabilization_videos/vid3-right.mp4'\n",
    "left_array, right_array = import_stereo_video(left_name, right_name, start_loss=50, end_loss=50, display=True, only_left=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-giant",
   "metadata": {},
   "source": [
    "# Finding transforms:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-vampire",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## KLT Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding transforms with KLT \n",
    "transforms = np.zeros((len(left_array)-1, 3), np.float32)\n",
    "\n",
    "for i in range(len(left_array)-1):\n",
    "    # completion tracker\n",
    "    clear_output(wait=True)\n",
    "    print(\"{}/{} - {}%\".format(i+2, len(left_array), np.round((i*100)/(len(left_array)-2), 1)))\n",
    "    \n",
    "    frameg = cv2.cvtColor(left_array[i], cv2.COLOR_RGB2GRAY)\n",
    "    prev_pts = cv2.goodFeaturesToTrack(frameg,\n",
    "                                     maxCorners=200,\n",
    "                                     qualityLevel=0.01,\n",
    "                                     minDistance=30,\n",
    "                                     blockSize=3)\n",
    "\n",
    "    # Calculate optical flow (i.e. track feature points)\n",
    "    curr_pts, status, err = cv2.calcOpticalFlowPyrLK(left_array[i], left_array[i+1], prev_pts, None)\n",
    "    \n",
    "    # Sanity check\n",
    "    assert prev_pts.shape == curr_pts.shape\n",
    "    \n",
    "    # Filter only valid points\n",
    "    idx = np.where(status==1)[0]\n",
    "    \n",
    "    prev_pts = prev_pts[idx]\n",
    "    curr_pts = curr_pts[idx]\n",
    "    \n",
    "    m, _ = cv2.estimateAffinePartial2D(prev_pts, curr_pts)\n",
    "    \n",
    "    # extract info from matrix\n",
    "    dx = m[0,2]\n",
    "    dy = m[1,2]\n",
    "    da = np.arctan2(m[1,0], m[0,0])\n",
    "\n",
    "    # create transform matrix\n",
    "    transforms[i] = [dx,dy,da]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-termination",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Super Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use superpoint and superglue to find matches between frames\n",
    "config = {\n",
    "        'superpoint': {\n",
    "            'nms_radius': 2,\n",
    "            'keypoint_threshold': 0.1,  #0\n",
    "            'max_keypoints': -1\n",
    "        },\n",
    "        'superglue': {\n",
    "            'weights': 'indoor',\n",
    "            'sinkhorn_iterations': 20,\n",
    "            'match_threshold': 0.2,  # 0.01\n",
    "        }\n",
    "    }\n",
    "\n",
    "# initializing matcher\n",
    "matcher = Matching(config).eval()#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding transforms with superpoint/glue\n",
    "transforms = np.zeros((len(left_array)-1, 3), np.float32)\n",
    "\n",
    "for i in range(len(left_array)-1):\n",
    "    # completion tracker\n",
    "    clear_output(wait=True)\n",
    "    print(\"{}/{} - {}%\".format(i+1, len(left_array)-1, np.round((i*100)/(len(left_array)-2), 1)))\n",
    "    \n",
    "    # use super point and super glue to find good points to track between frames\n",
    "    frame1, frame2, pts1, pts2 = find_points(matcher, left_array[i], left_array[i+1], display=False)\n",
    "    # can use a feature detection and then use KLT to find the same points in the next frame, I beleive my method is just as effective if not more\n",
    "    # however this method takes considerably longer to compute so probably not a smart option\n",
    "\n",
    "    m, _ = cv2.estimateAffinePartial2D(pts1, pts2)\n",
    "    \n",
    "    # extract info from matrix\n",
    "    dx = m[0,2]\n",
    "    dy = m[1,2]\n",
    "    da = np.arctan2(m[1,0], m[0,0])\n",
    "\n",
    "    # create transform matrix\n",
    "    transforms[i] = [dx,dy,da]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-crack",
   "metadata": {},
   "source": [
    "# Finding difference:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-sentence",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## smoothing path method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate trajectory, smooth out this trajectory\n",
    "# use cumulative sum \n",
    "trajectory = np.cumsum(transforms, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can plot the trajectories\n",
    "def plot_trajectory(trajectory):\n",
    "    fig, ax = plt.subplots(1,3, figsize=(20,5))\n",
    "\n",
    "    ax[0].plot(trajectory[:,0])\n",
    "    ax[0].set_title(\"x\")\n",
    "    ax[0].set_ylabel(\"x (pixels)\")\n",
    "    ax[0].set_xlabel(\"Frames\")\n",
    "    ax[1].plot(trajectory[:,1])\n",
    "    ax[1].set_title(\"y\")\n",
    "    ax[1].set_ylabel(\"y (pixels)\")\n",
    "    ax[1].set_xlabel(\"Frames\")\n",
    "    ax[2].plot(trajectory[:,2])\n",
    "    ax[2].set_title(\"rotation\")\n",
    "    ax[2].set_ylabel(\"y (pixels)\")\n",
    "    ax[2].set_xlabel(\"Frames\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now have 3 curves for the trajectory over time, now we need to smooth them using moving average filter\n",
    "def movingAverage(curve, radius):\n",
    "    window_size = 2*radius + 1 # both ways plus the point itseld\n",
    "    # filter\n",
    "    f = np.ones(window_size)/window_size\n",
    "    # Add padding to the boundaries\n",
    "    curve_pad = np.lib.pad(curve, (radius, radius), 'edge')\n",
    "    # Apply convolution\n",
    "    curve_smoothed = np.convolve(curve_pad, f, mode='same')\n",
    "    # Remove padding\n",
    "    curve_smoothed = curve_smoothed[radius:-radius]\n",
    "    return curve_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(trajectory, radius):\n",
    "    smoothed_trajectory = np.copy(trajectory)\n",
    "    # filter the x, y and angle curves\n",
    "    for i in range(3):\n",
    "        smoothed_trajectory[:,i] = movingAverage(trajectory[:,i], radius=radius)\n",
    "    return smoothed_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_trajectory = smooth(trajectory, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(trajectory)\n",
    "plot_trajectory(smoothed_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate difference between smoothed and normal trajectory\n",
    "difference = smoothed_trajectory - trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-polyester",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## zero movement method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate trajectory, zero out this trajectory\n",
    "# use cumulative sum \n",
    "trajectory = np.cumsum(transforms, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a difference to 0, smooth trajectory should be all at 0 movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = np.zeros_like(trajectory) - trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-digest",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# Stabilizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the difference to the transforms to get smoothed transformation between frames\n",
    "transforms_smooth = transforms + difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "stabilized_array = []\n",
    "\n",
    "# apply the smoothed transformation to every frame to get stabilized video\n",
    "for i in range(len(left_array)-1):\n",
    "    \n",
    "    dx = transforms_smooth[i,0]\n",
    "    dy = transforms_smooth[i,1]\n",
    "    da = transforms_smooth[i,2]\n",
    "    \n",
    "    # reconstruct the transformation matrix\n",
    "    m = np.zeros((2,3), np.float32)\n",
    "    m[0,0] = np.cos(da)\n",
    "    m[0,1] = -np.sin(da)\n",
    "    m[1,0] = np.sin(da)\n",
    "    m[1,1] = np.cos(da)\n",
    "    m[0,2] = dx\n",
    "    m[1,2] = dy\n",
    "    \n",
    "    # apply affine warping to frames\n",
    "    frame_stabilized = cv2.warpAffine(left_array[i], m, (2720, 1530))      #(640,480)\n",
    "\n",
    "    # save to array\n",
    "    stabilized_array.append(frame_stabilized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save stabilized array (convert to video on desktop)\n",
    "np.save(\"vid3.npy\", stabilized_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-density",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# Checking Stabilization (point tracking):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with array\n",
    "# find points\n",
    "# track point using klt over video\n",
    "# plot those points and see movement\n",
    "# compare movement of normal to stabilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = stabilized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set frame 1 and 2 and find points in frame 1 to track\n",
    "frame1 = array[0]\n",
    "frame1g = cv2.cvtColor(frame1, cv2.COLOR_RGB2GRAY)\n",
    "frame1gt = torch.from_numpy(frame1g/255.).float()[None, None]\n",
    "\n",
    "frame2 = array[1]\n",
    "frame2g = cv2.cvtColor(frame2, cv2.COLOR_RGB2GRAY)\n",
    "frame2gt = torch.from_numpy(frame2g/255.).float()[None, None]\n",
    "\n",
    "# use superpoint and superglue to find some points:\n",
    "config = {\n",
    "        'superpoint': {\n",
    "            'nms_radius': 2,\n",
    "            'keypoint_threshold': 0.1,  #0\n",
    "            'max_keypoints': -1\n",
    "        },\n",
    "        'superglue': {\n",
    "            'weights': 'indoor',\n",
    "            'sinkhorn_iterations': 20,\n",
    "            'match_threshold': 0.02,  # 0.01\n",
    "        }\n",
    "    }\n",
    "\n",
    "# initializing matcher\n",
    "matcher = Matching(config).eval()#.to(device)\n",
    "\n",
    "# finding matching points in first frame and second\n",
    "pred = matcher({'image0': frame1gt, 'image1': frame2gt})\n",
    "\n",
    "# get sections from output (pred)\n",
    "kp1 = pred['keypoints0'][0].cpu().numpy()\n",
    "kp2 = pred['keypoints1'][0].cpu().numpy()\n",
    "matches = pred['matches0'][0].cpu().numpy()\n",
    "confidence = pred['matching_scores0'][0].detach().cpu().numpy()\n",
    "\n",
    "# keep only the valid matches and make points from found kp\n",
    "valid = matches > -1\n",
    "pts1 = kp1[valid]\n",
    "pts2 = kp2[matches[valid]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_object_point(n, nadd, pts1, frame1):\n",
    "    # Create some random colors (100 of them)\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    # copies for drawing on\n",
    "    frame1c = frame1.copy()\n",
    "\n",
    "    # left drawing\n",
    "    for i in pts1[n:n+nadd]:\n",
    "        point = (i[0].astype(int), i[1].astype(int))\n",
    "        frame1c = cv2.circle(frame1c, point, 3, (0,255,0), -1)\n",
    "\n",
    "    # plot left and right\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    ax.imshow(frame1c)\n",
    "    ax.set_title('Left -> Right')\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    return n, nadd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, nadd = find_object_point(100, 1, pts1, array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# use points in frame 1 found using superpoint\n",
    "prev_pts = pts1[n:n+nadd]\n",
    "\n",
    "points = [prev_pts]\n",
    "\n",
    "for i in range(len(array)-1):\n",
    "    # completion tracker\n",
    "    clear_output(wait=True)\n",
    "    print(\"{}/{} - {}%\".format(i+2, len(left_array), np.round((i*100)/(len(left_array)-2), 1)))\n",
    "\n",
    "    # Calculate optical flow (i.e. track feature points)\n",
    "    curr_pts, status, err = cv2.calcOpticalFlowPyrLK(left_array[i], left_array[i+1], prev_pts, None, **lk_params)\n",
    "    \n",
    "    # Sanity check\n",
    "    assert prev_pts.shape == curr_pts.shape\n",
    "    \n",
    "    # Filter only valid points\n",
    "    idx = np.where(status==1)[0]\n",
    "    \n",
    "    prev_pts = prev_pts[idx]\n",
    "    curr_pts = curr_pts[idx]\n",
    "    \n",
    "    # save points \n",
    "    points.append(curr_pts)\n",
    "    \n",
    "    # set prev to current points for next iteration\n",
    "    prev_pts = curr_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array(points)\n",
    "points = points.reshape(points.shape[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(25,5))\n",
    "\n",
    "#ax[0].plot(point_beam[:, 0]-point_beam[0][0])\n",
    "ax[0].plot(points[:, 0]-points[0][0])\n",
    "ax[0].set_title(\"X\")\n",
    "\n",
    "#ax[1].plot(point_beam[:, 1]-point_beam[0][1])\n",
    "ax[1].plot(points[:, 1]-points[0][1])\n",
    "ax[1].set_title(\"Y\")\n",
    "\n",
    "#ax[2].scatter(point_beam[:, 0]-point_beam[0][0], point_beam[:, 1]-point_beam[0][1])\n",
    "ax[2].plot(points[:, 0]-points[0][0], points[:, 1]-points[0][1])\n",
    "ax[2].set_title(\"X vs Y\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-uncle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
